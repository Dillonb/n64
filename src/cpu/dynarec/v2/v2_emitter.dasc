#include <cpu/dynarec/v2/v2_emitter.h>
#include <cpu/dynarec/v2/v2_compiler.h>
#include <cpu/dynarec/v2/ir_optimizer.h>
#include <cpu/dynarec/v2/target_platform.h>
#include <cpu/dynarec/dynarec_memory_management.h>
#include <cpu/r4300i.h>

#include <dynasm/dasm_proto.h>
#ifndef N64_WIN
#include <sys/mman.h>
#include <cpu/dynarec/v2/x86_64_registers.h>
#include <r4300i_register_access.h>

#endif

#define TMPREG1 get_scratch_registers()[0]
#define TMPREG2 get_scratch_registers()[1]

#define TMPREG1_ALLOC alloc_gpr(get_scratch_registers()[0])
#define TMPREG2_ALLOC alloc_gpr(get_scratch_registers()[1])

#define IMM64_INVALID() logfatal("Should never end up here, x86_64 has no 64 bit immediates")

||#if ((defined(_M_X64) || defined(__amd64__)) != X64) || (defined(_WIN32) != WIN)
#error "Wrong DynASM flags used: pass `-D X64` and/or `-D WIN` to dynasm.lua as appropriate"
#endif

|.if X64
|.arch x64
|.else
|#error "Only x64 is supported"
|.endif

|.if X64
  |.define cpuState, r12
  |.if WIN
    |.define rArg1, rcx
    |.define rArg2, rdx
  |.else
    |.define rArg1, rdi
    |.define rArg2, rsi
  |.endif
  |.macro prepcall1, arg1
    | mov rArg1, arg1
  |.endmacro
  |.macro prepcall2, arg1, arg2
    | mov rArg1, arg1
    | mov rArg2, arg2
  |.endmacro
  |.define postcall, .nop
    // Called before our block
    |.macro prologue
      | sub rsp, (SPILL_SPACE_SIZE_BYTES + 8)
    |.endmacro
    // Called at the end of our block
    |.macro epilogue
      | add rsp, (SPILL_SPACE_SIZE_BYTES + 8)
      | ret
    |.endmacro
|.endif // TODO ARM version?
|.type cpu_state, r4300i_t, cpuState
|.type rsp_state, rsp_t, cpuState

dasm_State* v2_block_header() {
    dasm_State* d;
    unsigned npc = 8; // number of dynamic labels

    |.section code
    dasm_init(&d, DASM_MAXSECTION);

    |.globals lbl_

    void* labels[lbl__MAX];
    dasm_setupglobal(&d, labels, lbl__MAX);

    |.actionlist actions
    dasm_setup(&d, actions);
    dasm_growpc(&d, npc);

    dasm_State** Dst = &d;
    |.code
    |->compiled_block:
    | prologue
    return d;
}

int check_reg(ir_register_allocation_t reg, bool spill_ok) {
    unimplemented(!reg.allocated, "Register was not allocated!");
    if (reg.spilled) {
        if (!spill_ok) {
            logfatal("Register is spilled and caller does not handle this!");
        }
        unimplemented((reg.spill_location) < 0 || (reg.spill_location) > SPILL_SPACE_SIZE_BYTES, "Invalid spill location value: %d", reg.spill_location);
        return reg.spill_location;
    } else {
        unimplemented((reg.host_reg) < 0 || (reg.host_reg) > get_num_gprs(), "Invalid host register value: %d", reg.host_reg);
        return reg.host_reg;
    }
}

int check_fgr(ir_register_allocation_t reg, bool spill_ok) {
    if (reg.type != REGISTER_TYPE_FGR_32 && reg.type != REGISTER_TYPE_FGR_64) {
        logfatal("FGR expected, but register was not allocated as an FGR!");
    }
    return check_reg(reg, spill_ok);
}

int check_gpr(ir_register_allocation_t reg, bool spill_ok) {
    if (reg.type != REGISTER_TYPE_GPR) {
        logfatal("FGR expected, but register was not allocated as an FGR!");
    }
    return check_reg(reg, spill_ok);
}

void host_emit_mov_reg_imm(dasm_State** Dst, ir_register_allocation_t reg_alloc, ir_set_constant_t imm_value) {
    int reg = check_reg(reg_alloc, false);
    u64 value = set_const_to_u64(imm_value);
    if (imm_value.type == VALUE_TYPE_U64) {
        | mov64 Rq(reg), value
    } else {
        // DynASM will automatically detect sign extension here, and use the smallest possible immediate
        | mov Rq(reg), value
    }
}

void host_emit_and_reg_imm(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_set_constant_t operand2) {
    int operand1 = check_reg(operand1_alloc, true);
    if (operand1_alloc.spilled) {
        switch (operand2.type) {
            case VALUE_TYPE_S8:
                | and qword [rsp + operand1], operand2.value_s8
                break;
            case VALUE_TYPE_U8:
                | and qword [rsp + operand1], operand2.value_s8
                break;
            case VALUE_TYPE_S16:
                | and qword [rsp + operand1], operand2.value_s16
                break;
            case VALUE_TYPE_U16:
                | and qword [rsp + operand1], operand2.value_u16
                break;
            case VALUE_TYPE_S32:
                | and qword [rsp + operand1], operand2.value_s32
                break;
            case VALUE_TYPE_U32:
                | and qword [rsp + operand1], operand2.value_u32
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                IMM64_INVALID();
                break;
        }
    } else {
        switch (operand2.type) {
            case VALUE_TYPE_S8:
                | and Rq(operand1), operand2.value_s8
                break;
            case VALUE_TYPE_U8:
                | and Rq(operand1), operand2.value_s8
                break;
            case VALUE_TYPE_S16:
                | and Rq(operand1), operand2.value_s16
                break;
            case VALUE_TYPE_U16:
                | and Rq(operand1), operand2.value_u16
                break;
            case VALUE_TYPE_S32:
                | and Rq(operand1), operand2.value_s32
                break;
            case VALUE_TYPE_U32:
                | and Rq(operand1), operand2.value_u32
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                IMM64_INVALID();
                break;
        }
    }
}

void host_emit_and_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc) {
    int operand1 = check_reg(operand1_alloc, false);
    int operand2 = check_reg(operand2_alloc, false);
    | and Rq(operand1), Rq(operand2)
}

void host_emit_or_reg_imm(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_set_constant_t operand2) {
    int operand1 = check_reg(operand1_alloc, false);
    switch (operand2.type) {
        case VALUE_TYPE_S8:
            | or Rq(operand1), operand2.value_s8
            break;
        case VALUE_TYPE_U8:
            | or Rq(operand1), operand2.value_s8
            break;
        case VALUE_TYPE_S16:
            | or Rq(operand1), operand2.value_s16
            break;
        case VALUE_TYPE_U16:
            | or Rq(operand1), operand2.value_u16
            break;
        case VALUE_TYPE_S32:
            | or Rq(operand1), operand2.value_s32
            break;
        case VALUE_TYPE_U32:
            | or Rq(operand1), operand2.value_u32
            break;
        case VALUE_TYPE_U64:
        case VALUE_TYPE_S64:
            IMM64_INVALID();
            break;
    }
}

void host_emit_or_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc) {
    int operand1 = check_reg(operand1_alloc, true);
    int operand2 = check_reg(operand2_alloc, true);
    if (operand1_alloc.spilled && operand2_alloc.spilled) {
        logfatal("Both spilled");
    } else if (operand1_alloc.spilled) {
        | or qword [rsp + operand1], Rq(operand2)
    } else if (operand2_alloc.spilled) {
        logfatal("operand2 spilled");
    } else {
        | or Rq(operand1), Rq(operand2)
    }
}

void host_emit_xor_reg_imm(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_set_constant_t operand2) {
    int operand1 = check_reg(operand1_alloc, false);
    switch (operand2.type) {
        case VALUE_TYPE_S8:
            | xor Rq(operand1), operand2.value_s8
            break;
        case VALUE_TYPE_U8:
            | xor Rq(operand1), operand2.value_s8
            break;
        case VALUE_TYPE_S16:
            | xor Rq(operand1), operand2.value_s16
            break;
        case VALUE_TYPE_U16:
            | xor Rq(operand1), operand2.value_u16
            break;
        case VALUE_TYPE_S32:
            | xor Rq(operand1), operand2.value_s32
            break;
        case VALUE_TYPE_U32:
            | xor Rq(operand1), operand2.value_u32
            break;
        case VALUE_TYPE_U64:
        case VALUE_TYPE_S64:
            IMM64_INVALID();
            break;
    }
}

void host_emit_xor_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc) {
    int operand1 = check_reg(operand1_alloc, false);
    int operand2 = check_reg(operand2_alloc, false);
    | xor Rq(operand1), Rq(operand2)
}

void host_emit_add_reg_imm(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_set_constant_t operand2) {
    int operand1 = check_reg(operand1_alloc, false);
    switch (operand2.type) {
        case VALUE_TYPE_S8:
            | add Rq(operand1), operand2.value_s8
            break;
        case VALUE_TYPE_U8:
            | add Rq(operand1), operand2.value_s8
            break;
        case VALUE_TYPE_S16:
            | add Rq(operand1), operand2.value_s16
            break;
        case VALUE_TYPE_U16:
            | add Rq(operand1), operand2.value_u16
            break;
        case VALUE_TYPE_S32:
            | add Rq(operand1), operand2.value_s32
            break;
        case VALUE_TYPE_U32:
            | add Rq(operand1), operand2.value_u32
            break;
        case VALUE_TYPE_U64:
        case VALUE_TYPE_S64:
            IMM64_INVALID();
            break;
    }
}

void host_emit_add_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc) {
    int operand1 = check_reg(operand1_alloc, true);
    int operand2 = check_reg(operand2_alloc, true);
    if (operand1_alloc.spilled && operand2_alloc.spilled) {
        | mov Rq(TMPREG1), qword [rsp + operand2]
        | add qword [rsp + operand1], Rq(TMPREG1)
    } else if (operand1_alloc.spilled) {
        | add qword [rsp + operand1], Rq(operand2)
    } else if (operand2_alloc.spilled) {
        | add Rq(operand1), qword [rsp + operand2]
    } else {
        | add Rq(operand1), Rq(operand2)
    }
}

void host_emit_sub_reg_reg(dasm_State** Dst, ir_register_allocation_t minuend_alloc, ir_register_allocation_t subtrahend_alloc) {
    int minuend = check_reg(minuend_alloc, false);
    int subtrahend = check_reg(subtrahend_alloc, false);
    | sub Rq(minuend), Rq(subtrahend)
}

void host_emit_shift_reg_imm(dasm_State** Dst, ir_register_allocation_t reg_alloc, ir_value_type_t type, u8 shift_amount, ir_shift_direction_t direction) {
    int reg = check_reg(reg_alloc, false);
    switch (type) {
        case VALUE_TYPE_S8:
        case VALUE_TYPE_U8:
            logfatal("Shift 8 bit value");
            break;
        case VALUE_TYPE_S16:
        case VALUE_TYPE_U16:
            logfatal("Shift 16 bit value");
            break;

        case VALUE_TYPE_S32:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | sal Rd(reg), shift_amount
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | sar Rd(reg), shift_amount
                    break;
            }
            break;

        case VALUE_TYPE_U32:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | shl Rd(reg), shift_amount
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | shr Rd(reg), shift_amount
                    break;
            }
            break;

        case VALUE_TYPE_U64:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | shl Rq(reg), shift_amount
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | shr Rq(reg), shift_amount
                    break;
            }
            break;

        case VALUE_TYPE_S64:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | sal Rq(reg), shift_amount
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | sar Rq(reg), shift_amount
                    break;
            }
            break;
    }
}

void host_emit_shift_reg_reg(dasm_State** Dst, ir_register_allocation_t reg_alloc, ir_value_type_t type, ir_register_allocation_t amount_reg_alloc, ir_shift_direction_t direction) {
    int reg = check_reg(reg_alloc, false);
    int amount_reg = check_reg(amount_reg_alloc, false);
    | mov cl, Rb(amount_reg)
    switch (type) {
        case VALUE_TYPE_S8:
        case VALUE_TYPE_U8:
            logfatal("Shift 8 bit value");
            break;
        case VALUE_TYPE_S16:
        case VALUE_TYPE_U16:
            logfatal("Shift 16 bit value");
            break;

        case VALUE_TYPE_S32:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | sal Rd(reg), cl
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | sar Rd(reg), cl
                    break;
            }
            break;

        case VALUE_TYPE_U32:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | shl Rd(reg), cl
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | shr Rd(reg), cl
                    break;
            }
            break;

        case VALUE_TYPE_U64:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | shl Rq(reg), cl
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | shr Rq(reg), cl
                    break;
            }
            break;

        case VALUE_TYPE_S64:
            switch (direction) {
                case SHIFT_DIRECTION_LEFT:
                    | sal Rq(reg), cl
                    break;
                case SHIFT_DIRECTION_RIGHT:
                    | sar Rq(reg), cl
                    break;
            }
            break;
    }
}

void host_emit_bitwise_not(dasm_State** Dst, ir_register_allocation_t reg_alloc) {
    int reg = check_reg(reg_alloc, false);
    | not Rq(reg)
}

void host_emit_mult_reg_imm(dasm_State** Dst, ir_register_allocation_t reg_alloc, ir_set_constant_t imm, ir_value_type_t multiplicand_type) {
    int reg = check_reg(reg_alloc, false);
    u64 imm_value = set_const_to_u64(imm);
    switch (multiplicand_type) {
        case VALUE_TYPE_U8:
        case VALUE_TYPE_S8:
        case VALUE_TYPE_S16:
        case VALUE_TYPE_U16:
            logfatal("Smaller than 32 bit multiply");
            break;

        case VALUE_TYPE_S32:
            host_emit_mov_reg_imm(Dst, alloc_gpr(REG_RAX), imm);
            // mul writes the low 32 bits to eax, and the high 32 to edx.
            | imul Rd(reg)
            // Sign extend results
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RDX), alloc_gpr(REG_RDX), VALUE_TYPE_S32);
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RAX), alloc_gpr(REG_RAX), VALUE_TYPE_S32);
            // Save results to mem
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_hi, alloc_gpr(REG_RDX), VALUE_TYPE_U64);
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_lo, alloc_gpr(REG_RAX), VALUE_TYPE_U64);
            break;
        case VALUE_TYPE_U32:
            host_emit_mov_reg_imm(Dst, alloc_gpr(REG_RAX), imm);
            // mul writes the low 32 bits to eax, and the high 32 to edx.
            | mul Rd(reg)
            // Sign extend results
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RDX), alloc_gpr(REG_RDX), VALUE_TYPE_S32);
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RAX), alloc_gpr(REG_RAX), VALUE_TYPE_S32);
            // Save results to mem
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_hi, alloc_gpr(REG_RDX), VALUE_TYPE_U64);
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_lo, alloc_gpr(REG_RAX), VALUE_TYPE_U64);
            break;
        case VALUE_TYPE_U64:
            logfatal("u64 multiply");
        case VALUE_TYPE_S64:
            logfatal("s64 multiply");
            break;
    }
}

void host_emit_mult_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc, ir_value_type_t multiplicand_type) {
    int operand1 = check_reg(operand1_alloc, true);
    int operand2 = check_reg(operand2_alloc, true);

    switch (multiplicand_type) {
        case VALUE_TYPE_U8:
        case VALUE_TYPE_S8:
        case VALUE_TYPE_S16:
        case VALUE_TYPE_U16:
            logfatal("Smaller than 32 bit multiply");
        case VALUE_TYPE_S32:
            if (operand1_alloc.spilled) {
                | mov eax, dword [rsp + operand1]
            } else {
                | mov eax, Rd(operand1)
            }

            if (operand2_alloc.spilled) {
                | imul dword [rsp + operand2]
            } else {
                | imul Rd(operand2)
            }

            // Sign extend results
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RDX), alloc_gpr(REG_RDX), VALUE_TYPE_S32);
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RAX), alloc_gpr(REG_RAX), VALUE_TYPE_S32);
            // Save results to mem
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_hi, alloc_gpr(REG_RDX), VALUE_TYPE_U64);
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_lo, alloc_gpr(REG_RAX), VALUE_TYPE_U64);

            break;
        case VALUE_TYPE_U32:
            logfatal("u32 multiply");
        case VALUE_TYPE_U64:
            logfatal("u64 multiply");
        case VALUE_TYPE_S64:
            logfatal("s64 multiply");
    }
}

void host_emit_div_reg_imm(dasm_State** Dst, ir_register_allocation_t reg_alloc, ir_set_constant_t imm, ir_value_type_t multiplicand_type) {
    logfatal("host_emit_div_reg_imm");
}

void host_emit_div_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc, ir_value_type_t divide_type) {
    int operand1 = check_reg(operand1_alloc, true);
    int operand2 = check_reg(operand2_alloc, true);

    switch (divide_type) {
        case VALUE_TYPE_U8:
        case VALUE_TYPE_S8:
        case VALUE_TYPE_S16:
        case VALUE_TYPE_U16:
            logfatal("Smaller than 32 bit divide");
        case VALUE_TYPE_S32:
            if (operand1_alloc.spilled) {
                | movsxd rax, dword [rsp + operand1]
            } else {
                | movsxd rax, Rd(operand1)
            }
            | cqo

            if (operand2_alloc.spilled) {
                | movsxd Rq(TMPREG2), dword [rsp + operand2]
            } else {
                | movsxd Rq(TMPREG2), Rd(operand2)
            }
            | test Rq(TMPREG2), Rq(TMPREG2)
            | jz >1
            | idiv Rq(TMPREG2)

            // Sign extend results
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RDX), alloc_gpr(REG_RDX), VALUE_TYPE_S32);
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RAX), alloc_gpr(REG_RAX), VALUE_TYPE_S32);

            | jmp >2
            |1:
            // Divide by zero
            // Dividend into RDX, which will be moved to mult_hi below TODO just save it here
            | mov rdx, rax
            // If divisor is negative
            | test rax, rax
            | js >3
            | mov rax, -1
            | jmp >2
            |3:
            | mov rax, 1
            |2:
            // Save results to mem
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_hi, alloc_gpr(REG_RDX), VALUE_TYPE_U64);
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_lo, alloc_gpr(REG_RAX), VALUE_TYPE_U64);
            break;
        case VALUE_TYPE_U32:
            if (operand1_alloc.spilled) {
                | mov eax, dword [rsp + operand1]
            } else {
                | mov eax, Rd(operand1)
            }
            | cqo

            if (operand2_alloc.spilled) {
                | mov Rd(TMPREG2), dword [rsp + operand2]
            } else {
                | mov Rd(TMPREG2), Rd(operand2)
            }
            | test Rq(TMPREG2), Rq(TMPREG2)
            | jz >1
            | div Rq(TMPREG2)

            // Sign extend results
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RDX), alloc_gpr(REG_RDX), VALUE_TYPE_S32);
            host_emit_mov_reg_reg(Dst, alloc_gpr(REG_RAX), alloc_gpr(REG_RAX), VALUE_TYPE_S32);

            | jmp >2
            |1:
            // Divide by zero
            // Dividend into RDX, which will be moved to mult_hi below TODO just save it here
            | mov rdx, rax
            | mov rax, -1
            |2:
            // Save results to mem
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_hi, alloc_gpr(REG_RDX), VALUE_TYPE_U64);
            host_emit_mov_mem_reg(Dst, (uintptr_t)&N64CPU.mult_lo, alloc_gpr(REG_RAX), VALUE_TYPE_U64);
            break;
        case VALUE_TYPE_U64:
            logfatal("u64 divide");
        case VALUE_TYPE_S64:
            logfatal("s64 divide");
    }
}

void host_emit_mov_reg_reg(dasm_State** Dst, ir_register_allocation_t dst_reg_alloc, ir_register_allocation_t src_reg_alloc, ir_value_type_t source_value_type) {
    if (source_value_type == VALUE_TYPE_U64 && reg_alloc_equal(src_reg_alloc, dst_reg_alloc)) {
        return;
    }
    if (dst_reg_alloc.type == REGISTER_TYPE_FGR_32 || dst_reg_alloc.type == REGISTER_TYPE_FGR_64) {
        unimplemented(src_reg_alloc.type != REGISTER_TYPE_GPR, "non-GPR source reg");
        host_emit_mov_fgr_gpr(Dst, dst_reg_alloc, src_reg_alloc, source_value_type);
        return;
    }
    if (src_reg_alloc.type == REGISTER_TYPE_FGR_32 || src_reg_alloc.type == REGISTER_TYPE_FGR_64) {
        unimplemented(dst_reg_alloc.type != REGISTER_TYPE_GPR, "non-GPR dest reg");
        host_emit_mov_gpr_fgr(Dst, dst_reg_alloc, src_reg_alloc, source_value_type);
        return;
    }
    unimplemented(dst_reg_alloc.type != REGISTER_TYPE_GPR, "non-GPR dest reg");

    unimplemented(dst_reg_alloc.spilled && src_reg_alloc.spilled, "both regs spilled");

    int dst = check_reg(dst_reg_alloc, true);
    int src = check_reg(src_reg_alloc, true);

    if (dst_reg_alloc.spilled) {
        switch (source_value_type) {
            case VALUE_TYPE_S8:
                | movsx Rq(TMPREG1), Rb(src)
                break;
            case VALUE_TYPE_U8:
                | movzx Rq(TMPREG1), Rb(src)
                break;
            case VALUE_TYPE_S16:
                | movsx Rq(TMPREG1), Rw(src)
                break;
            case VALUE_TYPE_U16:
                | movzx Rq(TMPREG1), Rw(src)
                break;
            case VALUE_TYPE_S32:
                | movsxd Rq(TMPREG1), Rd(src)
                break;
            case VALUE_TYPE_U32:
                // Writing to a 32 bit reg zero extends to the 64 bit reg
                | mov Rd(TMPREG1), Rd(src)
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                | mov Rq(TMPREG1), Rq(src)
                break;
        }
        | mov qword [rsp + dst], Rq(TMPREG1)
    } else if (src_reg_alloc.spilled) {
        switch (source_value_type) {
            case VALUE_TYPE_S8:
                | movsx Rq(dst), byte [rsp + src]
                break;
            case VALUE_TYPE_U8:
                | movzx Rq(dst), byte [rsp + src]
                break;
            case VALUE_TYPE_S16:
                | movsx Rq(dst), word [rsp + src]
                break;
            case VALUE_TYPE_U16:
                | movzx Rd(dst), word [rsp + src]
                break;
            case VALUE_TYPE_S32:
                | movsxd Rq(dst), dword [rsp + src]
                break;
            case VALUE_TYPE_U32:
                // Writing to a 32 bit reg zero extends to the 64 bit reg
                | mov Rd(dst), dword [rsp + src]
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                | mov Rq(dst), qword [rsp + src]
                break;
        }
    } else {
        switch (source_value_type) {
            case VALUE_TYPE_S8:
                | movsx Rq(dst), Rb(src)
                break;
            case VALUE_TYPE_U8:
                | movzx Rq(dst), Rb(src)
                break;
            case VALUE_TYPE_S16:
                | movsx Rq(dst), Rw(src)
                break;
            case VALUE_TYPE_U16:
                | movzx Rq(dst), Rw(src)
                break;
            case VALUE_TYPE_S32:
                | movsxd Rq(dst), Rd(src)
                break;
            case VALUE_TYPE_U32:
                // Writing to a 32 bit reg zero extends to the 64 bit reg
                | mov Rd(dst), Rd(src)
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                | mov Rq(dst), Rq(src)
                break;
        }
    }
}

void host_emit_call(dasm_State** Dst, uintptr_t function) {
    | mov64 Rq(TMPREG1), function
    | call Rq(TMPREG1)
}

void host_emit_eret(dasm_State** Dst) {
    | test dword cpu_state->cp0.status.raw, STATUS_ERL_MASK
    | jz >1
        | mov Rq(TMPREG1), cpu_state->cp0.error_epc
        | mov cpu_state->pc, Rq(TMPREG1)
        | add Rq(TMPREG1), 4
        | mov cpu_state->next_pc, Rq(TMPREG1)
        | and dword cpu_state->cp0.status.raw, (~STATUS_ERL_MASK)
    | jmp >2
    |1:
        | mov Rq(TMPREG1), cpu_state->cp0.EPC
        | mov cpu_state->pc, Rq(TMPREG1)
        | add Rq(TMPREG1), 4
        | mov cpu_state->next_pc, Rq(TMPREG1)
        | and dword cpu_state->cp0.status.raw, (~STATUS_EXL_MASK)
    |2:
    logwarn("Emitting ERET without running cp0_status_updated()");
    //cp0_status_updated();
    static_assert(sizeof(bool) == 1, "bool should be a byte");
    | mov byte cpu_state->llbit, 0
}

void host_emit_debugbreak(dasm_State** Dst) {
    | int3
}

void set_dest_cond(dasm_State** Dst, ir_register_allocation_t dest_reg_alloc, ir_condition_t cond, enum args_reversed args_reversed) {
    int dest_reg = check_reg(dest_reg_alloc, false);
    if (dest_reg >= 0) {
        switch (cond) {
            case CONDITION_NOT_EQUAL:
                | setne Rb(dest_reg)
                break;
            case CONDITION_EQUAL:
                | sete Rb(dest_reg)
                break;
            case CONDITION_LESS_THAN_SIGNED:
                if (args_reversed) {
                    | setg Rb(dest_reg)
                } else {
                    | setl Rb(dest_reg)
                }
                break;
            case CONDITION_LESS_THAN_UNSIGNED:
                if (args_reversed) {
                    | seta Rb(dest_reg)
                } else {
                    | setb Rb(dest_reg)
                }
                break;
            case CONDITION_GREATER_THAN_SIGNED:
                if (args_reversed) {
                    | setl Rb(dest_reg)
                } else {
                    | setg Rb(dest_reg)
                }
                break;
            case CONDITION_GREATER_THAN_UNSIGNED:
                if (args_reversed) {
                    | setb Rb(dest_reg)
                } else {
                    | seta Rb(dest_reg)
                }
                break;
            case CONDITION_LESS_OR_EQUAL_TO_SIGNED:
                if (args_reversed) {
                    | setg Rb(dest_reg)
                } else {
                    | setle Rb(dest_reg)
                }
                break;
            case CONDITION_LESS_OR_EQUAL_TO_UNSIGNED:
                if (args_reversed) {
                    | seta Rb(dest_reg)
                } else {
                    | setbe Rb(dest_reg)
                }
                break;
            case CONDITION_GREATER_OR_EQUAL_TO_SIGNED:
                if (args_reversed) {
                    | setl Rb(dest_reg)
                } else {
                    | setge Rb(dest_reg)
                }
                break;
            case CONDITION_GREATER_OR_EQUAL_TO_UNSIGNED:
                if (args_reversed) {
                    | setb Rb(dest_reg)
                } else {
                    | setae Rb(dest_reg)
                }
                break;
        }
    }
    | movzx Rq(dest_reg), Rb(dest_reg)
}

void host_emit_cmp_reg_imm(dasm_State** Dst, ir_register_allocation_t dest_reg_alloc, ir_condition_t cond, ir_register_allocation_t operand1_alloc, ir_set_constant_t operand2, enum args_reversed args_reversed) {
    int operand1 = check_reg(operand1_alloc, true);
    if (operand1_alloc.spilled) {
        switch (operand2.type) {
            case VALUE_TYPE_S8:
                | cmp qword [rsp + operand1], operand2.value_s8
                break;
            case VALUE_TYPE_U8:
                | cmp qword [rsp + operand1], operand2.value_u8
                break;
            case VALUE_TYPE_S16:
                | cmp qword [rsp + operand1], operand2.value_s16
                break;
            case VALUE_TYPE_U16:
                | cmp qword [rsp + operand1], operand2.value_u16
                break;
            case VALUE_TYPE_S32:
                | cmp qword [rsp + operand1], operand2.value_s32
                break;
            case VALUE_TYPE_U32:
                | cmp qword [rsp + operand1], operand2.value_u32
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                IMM64_INVALID();
                break;
        }
    } else {
        switch (operand2.type) {
            case VALUE_TYPE_S8:
                | cmp Rq(operand1), operand2.value_s8
                break;
            case VALUE_TYPE_U8:
                | cmp Rq(operand1), operand2.value_u8
                break;
            case VALUE_TYPE_S16:
                | cmp Rq(operand1), operand2.value_s16
                break;
            case VALUE_TYPE_U16:
                | cmp Rq(operand1), operand2.value_u16
                break;
            case VALUE_TYPE_S32:
                | cmp Rq(operand1), operand2.value_s32
                break;
            case VALUE_TYPE_U32:
                | cmp Rq(operand1), operand2.value_u32
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                IMM64_INVALID();
                break;
        }
    }
    set_dest_cond(Dst, dest_reg_alloc, cond, args_reversed);
}

void host_emit_cmp_reg_reg(dasm_State** Dst, ir_register_allocation_t dest_reg_alloc, ir_condition_t cond, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc, enum args_reversed args_reversed) {
    int operand1 = check_reg(operand1_alloc, true);
    int operand2 = check_reg(operand2_alloc, true);
    if (operand1_alloc.spilled && operand2_alloc.spilled) {
        | mov Rq(TMPREG1), qword [rsp + operand1]
        | cmp Rq(TMPREG1), qword [rsp + operand2]
    } else if (operand1_alloc.spilled) {
        logfatal("Operand1 spilled");
        | cmp qword [rsp + operand1], Rq(operand2)
    } else if (operand2_alloc.spilled) {
        | cmp Rq(operand1), qword [rsp + operand2]
    } else {
        | cmp Rq(operand1), Rq(operand2)
    }
    set_dest_cond(Dst, dest_reg_alloc, cond, args_reversed);
}

void host_emit_mov_pc(dasm_State** Dst, ir_instruction_t* value) {
    if (is_constant(value)) {
        u64 const_value = const_to_u64(value);
        | mov64 Rq(TMPREG2), const_value
        | mov cpu_state->pc, Rq(TMPREG2)
        | add Rq(TMPREG2), 4
        | mov cpu_state->next_pc, Rq(TMPREG2)
    } else if (value->reg_alloc.spilled) {
        logfatal("Mov to PC from spilled");
    } else {
        int reg = check_reg(value->reg_alloc, false);
        | mov Rq(TMPREG2), Rq(reg)
        | mov cpu_state->pc, Rq(TMPREG2)
        | add Rq(TMPREG2), 4
        | mov cpu_state->next_pc, Rq(TMPREG2)
    }
}

void host_emit_cmov_pc_binary(dasm_State** Dst, ir_register_allocation_t cond_register_alloc, ir_instruction_t* if_true, ir_instruction_t* if_false) {
    int cond_register = check_reg(cond_register_alloc, false);
    | test Rb(cond_register), Rb(cond_register)
    | jz >1
    host_emit_mov_pc(Dst, if_true);
    | jmp >2 // done
    |1:
    host_emit_mov_pc(Dst, if_false);
    |2:
}

// Gets the offset within N64CPU for a pointer, or negative if the pointer is not within n64cpu
int get_n64cpu_offset(uintptr_t absolute) {
    const uintptr_t n64cpu_addr = (uintptr_t)&N64CPU;
    const uintptr_t offset = absolute - n64cpu_addr;

    // Check if the pointer is within N64CPU
    if (absolute > n64cpu_addr && offset < sizeof(N64CPU)) {
        return offset;
    } else {
        return -1;
    }
}

void host_emit_mov_mem_imm(dasm_State** Dst, uintptr_t mem, ir_set_constant_t value, ir_value_type_t write_size) {
    int offset = get_n64cpu_offset(mem);
    u64 imm = set_const_to_u64(value);
    // Check if the pointer is within N64CPU
    if (offset > 0) {
        switch (write_size) {
            case VALUE_TYPE_U8:
            case VALUE_TYPE_S8:
                | mov byte [cpu_state + offset], (u8)imm
                break;
            case VALUE_TYPE_S16:
            case VALUE_TYPE_U16:
                | mov word [cpu_state + offset], (u16)imm
                break;
            case VALUE_TYPE_S32:
            case VALUE_TYPE_U32:
                | mov dword [cpu_state + offset], (u32)imm
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                host_emit_mov_reg_imm(Dst, TMPREG1_ALLOC, value);
                | mov [cpu_state + offset], Rq(TMPREG1)
                break;
        }
    } else {
        logfatal("Not within N64CPU");
        | mov64 Rq(TMPREG1), mem
        host_emit_mov_reg_imm(Dst, TMPREG2_ALLOC, value);
        | mov [Rq(TMPREG1)], Rq(TMPREG2)
    }
}

void host_emit_mov_mem_reg(dasm_State** Dst, uintptr_t mem, ir_register_allocation_t reg_alloc, ir_value_type_t type) {
    int reg = check_reg(reg_alloc, true);
    int offset = get_n64cpu_offset(mem);

    if (reg_alloc.spilled) {
        unimplemented(reg_alloc.type != REGISTER_TYPE_GPR, "spilled non-gpr to mem");
        | mov Rq(TMPREG2), qword [rsp + reg]
        reg = TMPREG2;
    }

    // Check if the pointer is within N64CPU
    if (offset > 0) {
        switch (reg_alloc.type) {
            case REGISTER_TYPE_NONE:
                logfatal("mov_mem_reg REGISTER_TYPE_NONE");
                break;
            case REGISTER_TYPE_GPR:
                switch (type) {
                    CASE_SIZE_8:
                        | mov [cpu_state + offset], Rb(reg)
                        break;
                    CASE_SIZE_16:
                        | mov [cpu_state + offset], Rw(reg)
                        break;
                    CASE_SIZE_32:
                        | mov [cpu_state + offset], Rd(reg)
                        break;
                    CASE_SIZE_64:
                        | mov [cpu_state + offset], Rq(reg)
                        break;
                }
                break;
            case REGISTER_TYPE_FGR_32:
                unimplemented(type != VALUE_TYPE_U32 && type != VALUE_TYPE_S32, "non-32 bit FGR_32 flush");
                | movd dword [cpu_state + offset], xmm(reg)
                break;
            case REGISTER_TYPE_FGR_64:
                unimplemented(type != VALUE_TYPE_U64 && type != VALUE_TYPE_S64, "non-64 bit FGR_64 flush");
                | movq qword [cpu_state + offset], xmm(reg)
                break;
        }
    } else {
        unimplemented(reg_alloc.type != REGISTER_TYPE_GPR, "non-GPR write not within N64CPU");
        unimplemented(type != VALUE_TYPE_U64, "non-64 bit write not within N64CPU");
        logfatal("Not within n64cpu");
        | mov64 Rq(TMPREG1), mem
        | mov [Rq(TMPREG1)], Rq(reg)
    }
}

void host_emit_mov_reg_mem(dasm_State** Dst, ir_register_allocation_t reg_alloc, uintptr_t mem, ir_value_type_t type) {
    int reg = check_reg(reg_alloc, true);
    int offset = get_n64cpu_offset(mem);

    if (reg_alloc.spilled) {
        | mov Rq(TMPREG2), qword [rsp + reg]
        reg = TMPREG2;
    }

    // Check if the pointer is within N64CPU
    if (offset > 0) {
        switch (type) {
            case VALUE_TYPE_U8:
                | mov Rb(reg), [cpu_state + offset]
                | movzx Rq(reg), Rb(reg)
                break;
            case VALUE_TYPE_S8:
                | mov Rb(reg), [cpu_state + offset]
                | movsx Rq(reg), Rb(reg)
                break;
            case VALUE_TYPE_S16:
                | mov Rw(reg), [cpu_state + offset]
                | movsx Rq(reg), Rw(reg)
                break;
            case VALUE_TYPE_U16:
                | mov Rw(reg), [cpu_state + offset]
                | movzx Rq(reg), Rw(reg)
                break;
            case VALUE_TYPE_S32:
                | mov Rd(reg), [cpu_state + offset]
                | movsxd Rq(reg), Rd(reg)
                break;
            case VALUE_TYPE_U32:
                | mov Rd(reg), [cpu_state + offset]
                break;
            case VALUE_TYPE_U64:
            case VALUE_TYPE_S64:
                | mov Rq(reg), [cpu_state + offset]
                break;
        }
    } else {
        unimplemented(type != VALUE_TYPE_U64, "non-64 bit read not within N64CPU");
        logfatal("Not within n64cpu");
        | mov64 Rq(TMPREG1), mem
        | mov Rq(reg), [TMPREG1]
    }

    if (reg_alloc.spilled) {
        | mov qword [rsp + reg_alloc.spill_location], Rq(TMPREG2)
    }
}

void host_emit_ret(dasm_State** Dst, ir_instruction_flush_t* flush_iter, int block_length) {
    while (flush_iter != NULL) {
        int guest_reg = flush_iter->guest_reg;
        uintptr_t dest;
        ir_value_type_t type;
        switch (ir_context.guest_reg_to_reg_type[guest_reg]) {
            case REGISTER_TYPE_NONE:
                logfatal("Flushing REGISTER_TYPE_NONE");
                break;
            case REGISTER_TYPE_GPR:
                dest = (uintptr_t)&N64CPU.gpr[flush_iter->guest_reg];
                type = VALUE_TYPE_U64;
                break;
            case REGISTER_TYPE_FGR_32:
                dest = get_fpu_register_ptr_word(guest_reg - IR_FGR_BASE);
                type = VALUE_TYPE_U32;
                break;
            case REGISTER_TYPE_FGR_64:
                dest = get_fpu_register_ptr_dword(guest_reg - IR_FGR_BASE);
                type = VALUE_TYPE_U64;
                break;
        }

        if (is_constant(flush_iter->item)) {
            host_emit_mov_mem_imm(Dst, dest, flush_iter->item->set_constant, type);
        } else {
            host_emit_mov_mem_reg(Dst, dest, flush_iter->item->reg_alloc, type);
        }

        flush_iter = flush_iter->next;
    }
    | mov eax, block_length
    | epilogue
}

void host_emit_cond_ret(dasm_State** Dst, ir_register_allocation_t cond_reg_alloc, ir_instruction_flush_t* flush_iter, int block_length) {
    int cond_reg = check_reg(cond_reg_alloc, false);
    | test Rq(cond_reg), Rq(cond_reg)
    | jz >1
    host_emit_ret(Dst, flush_iter, block_length);
    |1:
}

void host_emit_mov_fgr_gpr(dasm_State** Dst, ir_register_allocation_t dst_reg, ir_register_allocation_t src_reg, ir_value_type_t size) {
    int dst = check_fgr(dst_reg, false);
    int src = check_gpr(src_reg, false);

    switch (size) {
        CASE_SIZE_8:
            logfatal("Invalid 8 bit mov fgr, gpr");
        CASE_SIZE_16:
            logfatal("Invalid 16 bit mov fgr, gpr");
        CASE_SIZE_32:
            | movd xmm(dst), Rd(src)
            break;
        CASE_SIZE_64:
            | movd xmm(dst), Rq(src)
            break;
    }
}

void host_emit_mov_gpr_fgr(dasm_State** Dst, ir_register_allocation_t dst_reg, ir_register_allocation_t src_reg, ir_value_type_t size) {
    int dst = check_gpr(dst_reg, false);
    int src = check_fgr(src_reg, false);

    switch (size) {
        CASE_SIZE_8:
            logfatal("Invalid 8 bit mov gpr, fgr");
        CASE_SIZE_16:
            logfatal("Invalid 16 bit mov gpr, fgr");
        CASE_SIZE_32:
            | movd Rd(dst), xmm(src)
            break;
        CASE_SIZE_64:
            | movd Rq(dst), xmm(src)
            break;
    }
}

void host_emit_mov_fgr_fgr(dasm_State** Dst, ir_register_allocation_t dst_reg, ir_register_allocation_t src_reg, ir_float_value_type_t format) {
    int dst = check_fgr(dst_reg, false);
    int src = check_fgr(src_reg, false);
    if (dst == src) {
        logwarn("mov_fgr_fgr xmm(%d), xmm(%d) is a no-op, not emitting!", dst, src);
        return;
    }

    switch (format) {
        case FLOAT_VALUE_TYPE_INVALID:
            logfatal("host_emit_mov_fgr_fgr FLOAT_VALUE_TYPE_INVALID");
            break;
        case FLOAT_VALUE_TYPE_WORD:
            logfatal("host_emit_mov_fgr_fgr FLOAT_VALUE_TYPE_WORD");
            break;
        case FLOAT_VALUE_TYPE_LONG:
            logfatal("host_emit_mov_fgr_fgr FLOAT_VALUE_TYPE_LONG");
            break;
        case FLOAT_VALUE_TYPE_SINGLE:
            | movss xmm(dst), xmm(src)
            break;
        case FLOAT_VALUE_TYPE_DOUBLE:
            | movsd xmm(dst), xmm(src)
            break;
    }
}

void host_emit_float_convert_reg_reg(dasm_State** Dst, ir_float_value_type_t src_type, ir_register_allocation_t src_reg, ir_float_value_type_t dst_type, ir_register_allocation_t dst_reg) {
    int src = check_reg(src_reg, false);
    int dst = check_fgr(dst_reg, false);

    switch (src_type) {
        case FLOAT_VALUE_TYPE_INVALID:
            logfatal("Cannot convert from FLOAT_VALUE_TYPE_INVALID");
        case FLOAT_VALUE_TYPE_WORD:
            switch (dst_type) {
                case FLOAT_VALUE_TYPE_INVALID:
                    logfatal("Cannot convert to FLOAT_VALUE_TYPE_INVALID");
                    break;
                case FLOAT_VALUE_TYPE_WORD:
                    logfatal("Converting from FLOAT_VALUE_TYPE_WORD to FLOAT_VALUE_TYPE_WORD");
                    break;
                case FLOAT_VALUE_TYPE_LONG:
                    logfatal("Converting from FLOAT_VALUE_TYPE_WORD to FLOAT_VALUE_TYPE_LONG");
                    break;
                case FLOAT_VALUE_TYPE_SINGLE:
                    if (src_reg.type == REGISTER_TYPE_GPR) {
                        // cvtsi2ss gpr -> xmm
                        logfatal("Converting to word -> single from GPR: use cvtsi2ss");
                    } else if (src_reg.type == REGISTER_TYPE_FGR_64) {
                        logfatal("Converting to word -> single from FGR_64 - do I need to reload the source register?");
                    } else {
                        | cvtdq2ps xmm(dst), xmm(src)
                    }
                    break;
                case FLOAT_VALUE_TYPE_DOUBLE:
                    if (src_reg.type == REGISTER_TYPE_GPR) {
                        //cvtsi2sd gpr -> xmm
                        logfatal("Converting to word -> double from GPR: use cvtsi2sd");
                    } else if (src_reg.type == REGISTER_TYPE_FGR_64) {
                        logfatal("Converting to word -> double from FGR_64 - do I need to reload the source register?");
                    } else {
                        | cvtdq2pd xmm(dst), xmm(src)
                    }
                    break;
            }
            break;
        case FLOAT_VALUE_TYPE_LONG:
            switch (dst_type) {
                case FLOAT_VALUE_TYPE_INVALID:
                    logfatal("Cannot convert to FLOAT_VALUE_TYPE_INVALID");
                    break;
                case FLOAT_VALUE_TYPE_WORD:
                    logfatal("Converting from FLOAT_VALUE_TYPE_LONG to FLOAT_VALUE_TYPE_WORD");
                    break;
                case FLOAT_VALUE_TYPE_LONG:
                    logfatal("Converting from FLOAT_VALUE_TYPE_LONG to FLOAT_VALUE_TYPE_LONG");
                    break;
                case FLOAT_VALUE_TYPE_SINGLE:
                    if (src_reg.type == REGISTER_TYPE_GPR) {
                        | cvtsi2ss xmm(dst), Rq(src)
                    } else if (src_reg.type == REGISTER_TYPE_FGR_32) {
                        logfatal("Converting long -> single from FGR_32 - reload the source register");
                    } else {
                        | movd Rq(TMPREG1), xmm(src)
                        | cvtsi2ss xmm(dst), Rq(TMPREG1)
                    }
                    break;
                case FLOAT_VALUE_TYPE_DOUBLE:
                    if (src_reg.type == REGISTER_TYPE_GPR) {
                        | cvtsi2sd xmm(dst), Rq(src)
                    } else if (src_reg.type == REGISTER_TYPE_FGR_32) {
                        logfatal("Converting long -> double from FGR_32 - reload the source register");
                    } else {
                        | movd Rq(TMPREG1), xmm(src)
                        | cvtsi2sd xmm(dst), Rq(TMPREG1)
                    }
                    break;
            }
            break;
        case FLOAT_VALUE_TYPE_SINGLE:
            switch (dst_type) {
                case FLOAT_VALUE_TYPE_INVALID:
                    logfatal("Cannot convert to FLOAT_VALUE_TYPE_INVALID");
                    break;
                case FLOAT_VALUE_TYPE_WORD:
                    unimplemented(src_reg.type != REGISTER_TYPE_FGR_32, "converting from SINGLE to WORD with a non-FGR32 source");
                    unimplemented(dst_reg.type != REGISTER_TYPE_FGR_32, "converting from SINGLE to WORD with a non-FGR32 dest");
                    | cvttss2si Rd(TMPREG1), xmm(src)
                    | movd xmm(dst), Rq(TMPREG1)
                    break;
                case FLOAT_VALUE_TYPE_LONG:
                    unimplemented(src_reg.type != REGISTER_TYPE_FGR_32, "converting from SINGLE to LONG with a non-FGR32 source");
                    unimplemented(dst_reg.type != REGISTER_TYPE_FGR_64, "converting from SINGLE to LONG with a non-FGR64 dest");
                    | cvttss2si Rq(TMPREG1), xmm(src)
                    | movd xmm(dst), Rq(TMPREG1)
                    break;
                case FLOAT_VALUE_TYPE_SINGLE:
                    logfatal("Converting from FLOAT_VALUE_TYPE_SINGLE to FLOAT_VALUE_TYPE_SINGLE");
                    break;
                case FLOAT_VALUE_TYPE_DOUBLE:
                    unimplemented(src_reg.type != REGISTER_TYPE_FGR_32, "converting from SINGLE to DOUBLE with a non-FGR32 source");
                    unimplemented(dst_reg.type != REGISTER_TYPE_FGR_64, "converting from SINGLE to DOUBLE with a non-FGR64 dest");
                    | cvtss2sd xmm(dst), xmm(src)
                    break;
            }
            break;
        case FLOAT_VALUE_TYPE_DOUBLE:
            switch (dst_type) {
                case FLOAT_VALUE_TYPE_INVALID:
                    logfatal("Cannot convert to FLOAT_VALUE_TYPE_INVALID");
                    break;
                case FLOAT_VALUE_TYPE_WORD:
                    unimplemented(src_reg.type != REGISTER_TYPE_FGR_64, "converting from DOUBLE to WORD with a non-FGR64 source");
                    unimplemented(dst_reg.type != REGISTER_TYPE_FGR_32, "converting from DOUBLE to WORD with a non-FGR32 dest");
                    | cvttsd2si Rd(TMPREG1), xmm(src)
                    | movd xmm(dst), Rq(TMPREG1)
                    break;
                case FLOAT_VALUE_TYPE_LONG:
                    unimplemented(src_reg.type != REGISTER_TYPE_FGR_64, "converting from DOUBLE to LONG with a non-FGR64 source");
                    unimplemented(dst_reg.type != REGISTER_TYPE_FGR_64, "converting from DOUBLE to LONG with a non-FGR64 dest");
                    | cvttsd2si Rq(TMPREG1), xmm(src)
                    | movd xmm(dst), Rq(TMPREG1)
                    break;
                case FLOAT_VALUE_TYPE_SINGLE:
                    unimplemented(src_reg.type != REGISTER_TYPE_FGR_64, "converting from DOUBLE to SINGLE with a non-FGR64 source");
                    unimplemented(dst_reg.type != REGISTER_TYPE_FGR_32, "converting from DOUBLE to SINGLE with a non-FGR32 dest");
                    | pxor xmm(dst), xmm(dst)
                    | cvtsd2ss xmm(dst), xmm(src)
                    break;
                case FLOAT_VALUE_TYPE_DOUBLE:
                    logfatal("Converting from FLOAT_VALUE_TYPE_DOUBLE to FLOAT_VALUE_TYPE_DOUBLE");
                    break;
            }
            break;
    }
}

void host_emit_float_add_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc, ir_float_value_type_t format) {
    int operand1 = check_fgr(operand1_alloc, false);
    int operand2 = check_fgr(operand2_alloc, false);
    switch (format) {
        case FLOAT_VALUE_TYPE_INVALID:
            logfatal("host_emit_float_add_reg_reg FLOAT_VALUE_TYPE_INVALID");
            break;
        case FLOAT_VALUE_TYPE_WORD:
            logfatal("host_emit_float_add_reg_reg FLOAT_VALUE_TYPE_WORD");
            break;
        case FLOAT_VALUE_TYPE_LONG:
            logfatal("host_emit_float_add_reg_reg FLOAT_VALUE_TYPE_LONG");
            break;
        case FLOAT_VALUE_TYPE_SINGLE:
            | addss xmm(operand1), xmm(operand2)
            break;
        case FLOAT_VALUE_TYPE_DOUBLE:
            | addsd xmm(operand1), xmm(operand2)
            break;
    }
}

void host_emit_float_sub_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc, ir_float_value_type_t format) {
    logfatal("host_emit_float_sub_reg_reg");
}

void host_emit_float_div_reg_reg(dasm_State** Dst, ir_register_allocation_t operand1_alloc, ir_register_allocation_t operand2_alloc, ir_float_value_type_t format) {
    int dividend = check_fgr(operand1_alloc, false);
    int divisor = check_fgr(operand2_alloc, false);
    switch (format) {
        case FLOAT_VALUE_TYPE_INVALID:
            logfatal("host_emit_float_div_reg_reg FLOAT_VALUE_TYPE_INVALID");
            break;
        case FLOAT_VALUE_TYPE_WORD:
            logfatal("host_emit_float_div_reg_reg FLOAT_VALUE_TYPE_WORD");
            break;
        case FLOAT_VALUE_TYPE_LONG:
            logfatal("host_emit_float_div_reg_reg FLOAT_VALUE_TYPE_LONG");
            break;
        case FLOAT_VALUE_TYPE_SINGLE:
            | divss xmm(dividend), xmm(divisor)
            break;
        case FLOAT_VALUE_TYPE_DOUBLE:
            | divsd xmm(dividend), xmm(divisor)
            break;
    }
}

void v2_end_block(dasm_State** Dst, int block_length) {
    | mov eax, block_length
    | epilogue // return block_length
}

void* v2_link_and_encode(dasm_State** d, n64_dynarec_block_t* block, int guest_len) {
    size_t code_size;
    dasm_link(d, &code_size);
    u8* buf = dynarec_bumpalloc(code_size);
    dasm_encode(d, buf);

#ifdef N64_LOG_COMPILATIONS
    printf("Generated %ld bytes of code\n", code_size);
/*
    FILE* f = fopen("compiled.bin", "wb");
    fwrite(buf, 1, code_size, f);
    fclose(f);
    */
#endif

    block->run = (int(*)(r4300i_t *)) buf;
    block->guest_size = guest_len * 4;
    block->host_size = code_size;

    return buf;
}
